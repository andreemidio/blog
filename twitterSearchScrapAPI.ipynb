{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#referências\n",
    "#https://pythonprogramming.net/stop-words-nltk-tutorial/?completed=/tokenizing-words-sentences-nltk-tutorial/\n",
    "#bibioteca de analise de textos NLTK\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#biblioteca de manipulação de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#biblioteca de raspagem de dados do twitter\n",
    "#referência\n",
    "#https://pypi.python.org/pypi/TwitterSearch/\n",
    "from TwitterSearch import *\n",
    "try:\n",
    "\n",
    "    ts = TwitterSearch(\n",
    "        consumer_key = 'HS80eyaFqpCRVoRPM9XamL3Z0',\n",
    "        consumer_secret = 'pA7ZZ2dqJ7km7W1n2fv8jhM6pZUjiGJRDvv4SJtBkvzso6Yqi2',\n",
    "        access_token = '80844534-9Lc223LdtkvdLHT22z73C9rIf60N21WdwczHU2TFB',\n",
    "        access_token_secret = 'bOjGH3j9ZwNk7GYqltzZo6pGCY2PycjPo8X9ojY5IJVe1'\n",
    "     )\n",
    "\n",
    "    tso = TwitterSearchOrder()\n",
    "    tso.set_keywords(['#trump','#lula','#temer'])\n",
    "    tso.set_language('en')\n",
    "\n",
    "    #for tweet in ts.search_tweets_iterable(tso):\n",
    "       #print( '@%s tweeted: %s' % ( tweet['user']['screen_name'], tweet['text'] ) )\n",
    "        \n",
    "except TwitterSearchException as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "970305509663309825\n"
     ]
    }
   ],
   "source": [
    "print(tweet['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 2563727019, 'id_str': '2563727019', 'name': 'marilia.lima.alvaren', 'screen_name': 'AlvarenMarilia', 'location': '', 'description': 'advogada, mãe de filhas lindas, torcedora quase fanática do Clube Atlético Mineiro , amante eterna de Paris , São João Del Rey, e de todas as praias do mundo.', 'url': None, 'entities': {'description': {'urls': []}}, 'protected': False, 'followers_count': 158, 'friends_count': 214, 'listed_count': 11, 'created_at': 'Sun May 25 16:42:58 +0000 2014', 'favourites_count': 24374, 'utc_offset': None, 'time_zone': None, 'geo_enabled': True, 'verified': False, 'statuses_count': 30776, 'lang': 'pt', 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'C0DEED', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/880613294280716289/m9uqDdE1_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/880613294280716289/m9uqDdE1_normal.jpg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/2563727019/1478659314', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': False, 'default_profile': True, 'default_profile_image': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none'}\n"
     ]
    }
   ],
   "source": [
    "print(tweet['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advogada, mãe de filhas lindas, torcedora quase fanática do Clube Atlético Mineiro , amante eterna de Paris , São João Del Rey, e de todas as praias do mundo.\n",
      "None\n",
      "pt\n",
      "None\n",
      "False\n",
      "158\n",
      "214\n",
      "24374\n",
      "marilia.lima.alvaren\n",
      "None\n",
      "{'description': {'urls': []}}\n"
     ]
    }
   ],
   "source": [
    "#print(tweet['text'])\n",
    "#print(tweet['user']['location'])\n",
    "\n",
    "#print(tweet['user']['followers_count'])\n",
    "\n",
    "print(tweet['user']['description'])\n",
    "print(tweet['user']['url'])\n",
    "print(tweet['user']['lang'])\n",
    "print(tweet['user']['time_zone'])\n",
    "print(tweet['user']['protected'])\n",
    "print(tweet['user']['followers_count'])\n",
    "print(tweet['user']['friends_count'])\n",
    "print(tweet['user']['favourites_count'])\n",
    "print(tweet['user']['name'])\n",
    "print(tweet['user']['url'])\n",
    "print(tweet['user']['entities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([\n",
    "    [tweet['id'],tweet['user']['screen_name'],\n",
    "     tweet['user']['name'],\n",
    "     tweet['user']['url'],\n",
    "     tweet['user']['location'],\n",
    "     tweet['text'], \n",
    "     tweet['user']['followers_count'],\n",
    "     tweet['user']['lang'],\n",
    "     tweet['user']['description']\n",
    "    ] for tweet in ts.search_tweets_iterable(tso)],\n",
    "    columns = ['ID','user','Nome','Perfil','Localização', 'Tweet', 'Seguidores','Linguagem', 'Descrição']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>user</th>\n",
       "      <th>Nome</th>\n",
       "      <th>Perfil</th>\n",
       "      <th>Localização</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Seguidores</th>\n",
       "      <th>Linguagem</th>\n",
       "      <th>Descrição</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID, user, Nome, Perfil, Localização, Tweet, Seguidores, Linguagem, Descrição]\n",
       "Index: []"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "creatingCsv =pd.DataFrame.to_csv(df,sep=',',  \n",
    "                                 header=True, index=True,\n",
    "                                 mode='a',\n",
    "                                 encoding='utf-8',\n",
    "                                 path_or_buf='trumptemerlula_twittersearch_sentiments_analysis_tweetSearch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "removeHashtag = tweet['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @arte_prima: \"Não se trata de 1 Direito de #Lula mas de TODOS os Brasileiros \"\\nArt 5 da  CF...\\n\\nAgora é ler retardado, tipo Antagonista,…'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removeHashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resultadoSemHashtag = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",removeHashtag).split())\n",
    "resultadoSemHashtag = ' '.join(re.sub(\"#\",\" \",removeHashtag).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @arte_prima: \"Não se trata de 1 Direito de Lula mas de TODOS os Brasileiros \" Art 5 da CF... Agora é ler retardado, tipo Antagonista,…'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultadoSemHashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "removeRT  = ' '.join(re.sub(\"RT\",\" \",resultadoSemHashtag).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@arte_prima: \"Não se trata de 1 Direito de Lula mas de TODOS os Brasileiros \" Art 5 da CF... Agora é ler retardado, tipo Antagonista,…'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removeRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "removeAspas = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",resultadoSemHashtag).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT prima N o se trata de 1 Direito de Lula mas de TODOS os Brasileiros Art 5 da CF Agora ler retardado tipo Antagonista'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removeAspas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = TextBlob(removeRT).sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.0, subjectivity=0.0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@arte_prima: \"Não se trata de 1 Direito de Lula mas de TODOS os Brasileiros \" Art 5 da CF... Agora é ler retardado, tipo Antagonista,…']\n"
     ]
    }
   ],
   "source": [
    "print(sent_tokenize(removeRT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@', 'arte_prima', ':', '``', 'Não', 'se', 'trata', 'de', '1', 'Direito', 'de', 'Lula', 'mas', 'de', 'TODOS', 'os', 'Brasileiros', '``', 'Art', '5', 'da', 'CF', '...', 'Agora', 'é', 'ler', 'retardado', ',', 'tipo', 'Antagonista', ',', '…']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(removeRT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(stopwords.words('portuguese'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Essa', 'é', 'uma', 'frase', 'de', 'teste', ',', 'que', 'testa', 'muito', 'o', 'programa', 'que', 'é', 'rápido']\n",
      "['Essa', 'é', 'frase', 'teste', ',', 'testa', 'programa', 'é', 'rápido']\n"
     ]
    }
   ],
   "source": [
    "example_sent = \"Essa é uma frase de teste, que testa muito o programa que é rápido\"\n",
    "\n",
    "stop_words = set(stopwords.words('portuguese'))\n",
    "\n",
    "word_tokens = word_tokenize(example_sent)\n",
    "\n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "\n",
    "filtered_sentence = []\n",
    "\n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "\n",
    "print(word_tokens)\n",
    "print(filtered_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
